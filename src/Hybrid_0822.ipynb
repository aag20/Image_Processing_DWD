{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D,UpSampling3D, Conv3DTranspose, Flatten, Concatenate, Dense, TimeDistributed, Bidirectional, Input, Reshape  \n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70490b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=18000)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ce485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a954a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(images, sequence_length):\n",
    "    X = []\n",
    "    num_sequences = len(images) // sequence_length\n",
    "    for i in range(num_sequences):\n",
    "        start_idx = i * sequence_length\n",
    "        end_idx = start_idx + sequence_length\n",
    "        sequence_x = images[start_idx:end_idx]\n",
    "        X.append(sequence_x)\n",
    "\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f06de",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_df =  pd.read_parquet(\"/home/arman_abouali/Downloads/X_data.parquet\")\n",
    "parquet_df = parquet_df.sort_values(by='Key', ascending=True)\n",
    "parquet_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(parquet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e553d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'Value' column\n",
    "values = parquet_df['Value'].values\n",
    "\n",
    "width = 71\n",
    "length = 41\n",
    "\n",
    "X_images = np.zeros(shape=(len(values), width, length))\n",
    "for ind, val in enumerate(values):\n",
    "    X_images[ind, :, :] = np.stack(val,axis=1)\n",
    "X_images = np.where(X_images<0, 0, X_images)\n",
    "\n",
    "# X += np.random.normal(loc=0, scale=1, size=X.shape)\n",
    "\n",
    "y_df = pd.read_csv('test.csv', sep=';', parse_dates=['Zeit'])\n",
    "y_df.set_index('Zeit', inplace=True)\n",
    "y = y_df.loc['2016-08-01':'2017-08-31'][['Margarethenklippe_Pegel_now', 'Sennhuette_Pegel_now']].values\n",
    "# y = merged_df[['Margarethenklippe','Sennhuette']].values\n",
    "\n",
    "# Verify the shape of X\n",
    "print(f\"Shape of X: {X_images.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "y = scaler.fit_transform(y)\n",
    "print(f\"Shape of y_scaled: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d24986",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 4\n",
    "\n",
    "X_image_sequence = create_sequences(X_images, seq_length)[:-1, :, :]\n",
    "\n",
    "X_sensors_sequence = create_sequences(y, sequence_length=seq_length)\n",
    "\n",
    "y_sensors_sequence = X_sensors_sequence[1:, -1, :]\n",
    "\n",
    "X_sensors_sequence = X_sensors_sequence[:-1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6276c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(X_image_sequence.shape[0]*0.8)\n",
    "val_len = int(X_image_sequence.shape[0]*0.1)\n",
    "\n",
    "X_im_train = X_image_sequence[:train_len]\n",
    "X_im_val = X_image_sequence[train_len:train_len+val_len]\n",
    "X_im_test = X_image_sequence[train_len+val_len:]\n",
    "\n",
    "X_sen_train = X_sensors_sequence[:train_len]\n",
    "X_sen_val = X_sensors_sequence[train_len:train_len+val_len]\n",
    "X_sen_test = X_sensors_sequence[train_len+val_len:]\n",
    "\n",
    "im_max = np.max(X_im_train)\n",
    "sen_max = np.max(X_sen_train)\n",
    "\n",
    "\n",
    "X_im_train /= im_max\n",
    "X_im_val /= im_max\n",
    "X_im_test /= im_max\n",
    "\n",
    "X_sen_train /= sen_max\n",
    "X_sen_val /= sen_max\n",
    "X_sen_test /= sen_max\n",
    "\n",
    "\n",
    "y_train = y_sensors_sequence[:train_len]\n",
    "y_val = y_sensors_sequence[train_len:train_len+val_len]\n",
    "y_test = y_sensors_sequence[train_len+val_len:]\n",
    "\n",
    "\n",
    "# Reshape X data\n",
    "X_im_train = np.reshape(X_im_train, newshape = (-1, X_im_train.shape[1], X_im_train.shape[2], X_im_train.shape[3], 1))\n",
    "X_im_val = np.reshape(X_im_val, newshape = (-1, X_im_val.shape[1], X_im_val.shape[2], X_im_val.shape[3], 1))\n",
    "X_im_test = np.reshape(X_im_test, newshape = (-1, X_im_test.shape[1], X_im_test.shape[2], X_im_test.shape[3], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d182c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = X_im_train.shape[1]\n",
    "image_height = X_im_train.shape[2]\n",
    "image_width = X_im_train.shape[3]\n",
    "num_channels = X_im_train.shape[4]\n",
    "\n",
    "# Input for image sequences\n",
    "image_input = Input(shape=(sequence_length, image_height, image_width, num_channels))\n",
    "\n",
    "# Input for scalar sequences\n",
    "scalar_input = Input(shape=(sequence_length, 2))\n",
    "\n",
    "# Define the image processing branch\n",
    "image_branch = TimeDistributed(Conv2D(32, (3, 3), activation='relu'))(image_input)\n",
    "image_branch = TimeDistributed(MaxPooling2D((2, 2)))(image_branch)\n",
    "image_branch = TimeDistributed(Flatten())(image_branch)\n",
    "image_branch = LSTM(16)(image_branch)\n",
    "\n",
    "# Define the scalar sequence processing branch\n",
    "scalar_branch = LSTM(16)(scalar_input)\n",
    "\n",
    "# Concatenate the outputs of the two branches\n",
    "concatenated = Concatenate()([image_branch, scalar_branch])\n",
    "\n",
    "# Fully connected layers for further processing\n",
    "# dense_layer = Dense(128, activation='relu')(concatenated)\n",
    "output = Dense(2, activation='linear')(concatenated)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[image_input, scalar_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Print a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba47719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=[X_im_train, X_sen_train], y=y_train, epochs=1000, batch_size=256, validation_data=([X_im_val, X_sen_val], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f59d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a2276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = model.predict([X_im_train, X_sen_train])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# For the first column\n",
    "axes[0].plot(y_hat_train[:, 0], label='Predicted 0')\n",
    "axes[0].plot(y_train[:, 0], label='Reference 0', alpha=.5)\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Margarethenklippe_Pegel_now')\n",
    "\n",
    "# For the second column\n",
    "axes[1].plot(y_hat_train[:, 1], label='Predicted 1')\n",
    "axes[1].plot(y_train[:, 1], label='Reference 1', alpha=.5)\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Sennhuette_Pegel_now')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_val = model.predict([X_im_val, X_sen_val])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# For the first column\n",
    "axes[0].plot(y_hat_train[:, 0], label='Predicted 0')\n",
    "axes[0].plot(y_train[:, 0], label='Reference 0', alpha=.5)\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Margarethenklippe_Pegel_now')\n",
    "\n",
    "# For the second column\n",
    "axes[1].plot(y_hat_train[:, 1], label='Predicted 1')\n",
    "axes[1].plot(y_train[:, 1], label='Reference 1', alpha=.5)\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Sennhuette_Pegel_now')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac19f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = model.predict([X_im_test, X_sen_test])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# For the first column\n",
    "axes[0].plot(y_hat_train[:, 0], label='Predicted 0')\n",
    "axes[0].plot(y_train[:, 0], label='Reference 0', alpha=.5)\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Margarethenklippe_Pegel_now')\n",
    "\n",
    "# For the second column\n",
    "axes[1].plot(y_hat_train[:, 1], label='Predicted 1')\n",
    "axes[1].plot(y_train[:, 1], label='Reference 1', alpha=.5)\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Sennhuette_Pegel_now')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7156a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the metrics\n",
    "def mse(y_true, y_pred):\n",
    "    return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.abs(y_true - y_pred).mean()\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))\n",
    "\n",
    "def nse(y_true, y_pred):\n",
    "    return 1 - (np.sum((y_true - y_pred) ** 2) / np.sum((y_true - y_true.mean()) ** 2))\n",
    "\n",
    "def mbd(y_true, y_pred):\n",
    "    return np.mean(y_pred - y_true)\n",
    "\n",
    "datasets = {\n",
    "    'train': (y_train, y_hat_train),\n",
    "    'test': (y_test, y_hat_test),\n",
    "    'val': (y_val, y_hat_val)\n",
    "}\n",
    "\n",
    "for name, (y_true, y_pred) in datasets.items():\n",
    "    print(f\"Metrics for {name} dataset:\")\n",
    "    print(f\"MSE: {mse(y_true, y_pred)}\")\n",
    "    print(f\"RMSE: {rmse(y_true, y_pred)}\")\n",
    "    print(f\"MAE: {mae(y_true, y_pred)}\")\n",
    "    print(f\"SMAPE: {smape(y_true, y_pred)}\")\n",
    "    print(f\"NSE: {nse(y_true, y_pred)}\")\n",
    "    print(f\"MBD: {mbd(y_true, y_pred)}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names\n",
    "column_names = ['Margarethenklippe_Pegel_now','Sennhuette_Pegel_now']\n",
    "\n",
    "# Function to plot residuals\n",
    "def plot_residuals(y_true, y_pred, column_name):\n",
    "    residuals = y_true - y_pred\n",
    "    plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "    plt.axhline(0, color='r', linestyle='--')\n",
    "    plt.title(f\"Residual Plot for {column_name}\")\n",
    "    plt.xlabel(f\"Predicted Values for {column_name}\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.show()\n",
    "\n",
    "# Calculate residuals for each column\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_true_column = y_test[:, i]\n",
    "    y_pred_column = y_hat_test[:, i]\n",
    "    \n",
    "    plot_residuals(y_true_column, y_pred_column, column_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e593350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Die Projektionsebene schneidet die Erdkugel bei 60,0°N\n",
    "(ϕ0) 5. Das kartesische Koordinatensystem besitzt eine Größe von 900 km x 900 km und ist parallel\n",
    "zum 10,0°E-Meridian (λ0) ausgerichtet. Als Bezugspunkt wurde der Mittelpunkt des Komposnp.random.seed(42)  # For reproducibility\n",
    "custom_index = 200  \n",
    "sequence_length = 8 #2H\n",
    "\n",
    "# Actual and predicted values for the sequence\n",
    "actual_sequence = y_test[custom_index:custom_index + sequence_length]\n",
    "predicted_sequence = y_hat_test[custom_index:custom_index + sequence_length]\n",
    "\n",
    "# Plotting the selected sequence for both columns\n",
    "column_names = ['Margarethenklippe_Pegel_now','Sennhuette_Pegel_now']\n",
    "\n",
    "for i in range(2):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(actual_sequence[:, i], label='Actual', marker='o')\n",
    "    plt.plot(predicted_sequence[:, i], label='Predicted', marker='x')\n",
    "    plt.title(f\"Actual vs Predicted for {column_names[i]}\")\n",
    "    plt.xlabel(\"Time step\")\n",
    "    plt.ylabel(column_names[i])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # For reproducibility\n",
    "custom_index = 200  \n",
    "sequence_length = 24 #6H\n",
    "\n",
    "# Actual and predicted values for the sequence\n",
    "actual_sequence = y_test[custom_index:custom_index + sequence_length]\n",
    "predicted_sequence = y_hat_test[custom_index:custom_index + sequence_length]\n",
    "\n",
    "# Plotting the selected sequence for both columns\n",
    "column_names = ['Margarethenklippe_Pegel_now','Sennhuette_Pegel_now']\n",
    "\n",
    "for i in range(2):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(actual_sequence[:, i], label='Actual', marker='o')\n",
    "    plt.plot(predicted_sequence[:, i], label='Predicted', marker='x')\n",
    "    plt.title(f\"Actual vs Predicted for {column_names[i]}\")\n",
    "    plt.xlabel(\"Time step\")\n",
    "    plt.ylabel(column_names[i])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cde872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
